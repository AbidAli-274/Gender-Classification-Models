{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyP_rqvNzkgd",
        "outputId": "bc5657a8-061e-4477-e2b9-38b62fb3cd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = os.path.join('/content/gdrive/MyDrive/faces2/', 'Training')\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150, 150),class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQFmK7qTzs2-",
        "outputId": "89151e85-d9f1-4225-d0aa-ac3a6edf9186"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2051 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150, 150),class_mode='categorical')\n",
        "validation_dir = os.path.join('/content/gdrive/MyDrive/faces2/', 'Validation')\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir,target_size=(150, 150),class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myITtjrDzuVs",
        "outputId": "efc94dbf-93bd-43d6-fe88-a57e0b75ecf2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 819 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(40, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "AQNuZ906z8x6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])"
      ],
      "metadata": {
        "id": "aZLA3M8Lzyt0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20  # Increase the number of epochs for better training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaC1l-kszywC",
        "outputId": "5e5076f2-5cb2-4759-e510-2ea5c64d4e74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "65/65 [==============================] - 450s 7s/step - loss: 0.6775 - acc: 0.5597 - val_loss: 0.5276 - val_acc: 0.7680\n",
            "Epoch 2/20\n",
            "65/65 [==============================] - 150s 2s/step - loss: 0.6152 - acc: 0.6860 - val_loss: 0.5839 - val_acc: 0.7509\n",
            "Epoch 3/20\n",
            "65/65 [==============================] - 145s 2s/step - loss: 0.5904 - acc: 0.7040 - val_loss: 0.5068 - val_acc: 0.7705\n",
            "Epoch 4/20\n",
            "65/65 [==============================] - 153s 2s/step - loss: 0.5943 - acc: 0.6880 - val_loss: 0.4980 - val_acc: 0.7790\n",
            "Epoch 5/20\n",
            "65/65 [==============================] - 146s 2s/step - loss: 0.5949 - acc: 0.6914 - val_loss: 0.4567 - val_acc: 0.8205\n",
            "Epoch 6/20\n",
            "65/65 [==============================] - 148s 2s/step - loss: 0.5646 - acc: 0.7250 - val_loss: 0.4501 - val_acc: 0.8156\n",
            "Epoch 7/20\n",
            "65/65 [==============================] - 151s 2s/step - loss: 0.5687 - acc: 0.7148 - val_loss: 0.5050 - val_acc: 0.7521\n",
            "Epoch 8/20\n",
            "65/65 [==============================] - 153s 2s/step - loss: 0.5572 - acc: 0.7275 - val_loss: 0.4550 - val_acc: 0.7998\n",
            "Epoch 9/20\n",
            "65/65 [==============================] - 146s 2s/step - loss: 0.5512 - acc: 0.7289 - val_loss: 0.4334 - val_acc: 0.8254\n",
            "Epoch 10/20\n",
            "65/65 [==============================] - 148s 2s/step - loss: 0.5232 - acc: 0.7455 - val_loss: 0.4174 - val_acc: 0.8095\n",
            "Epoch 11/20\n",
            "65/65 [==============================] - 153s 2s/step - loss: 0.5314 - acc: 0.7309 - val_loss: 0.4370 - val_acc: 0.8071\n",
            "Epoch 12/20\n",
            "65/65 [==============================] - 146s 2s/step - loss: 0.5345 - acc: 0.7392 - val_loss: 0.4124 - val_acc: 0.8352\n",
            "Epoch 13/20\n",
            "65/65 [==============================] - 152s 2s/step - loss: 0.5194 - acc: 0.7489 - val_loss: 0.4345 - val_acc: 0.7937\n",
            "Epoch 14/20\n",
            "65/65 [==============================] - 153s 2s/step - loss: 0.4994 - acc: 0.7645 - val_loss: 0.4365 - val_acc: 0.8095\n",
            "Epoch 15/20\n",
            "65/65 [==============================] - 146s 2s/step - loss: 0.4994 - acc: 0.7606 - val_loss: 0.3876 - val_acc: 0.8303\n",
            "Epoch 16/20\n",
            "65/65 [==============================] - 148s 2s/step - loss: 0.5038 - acc: 0.7582 - val_loss: 0.3836 - val_acc: 0.8486\n",
            "Epoch 17/20\n",
            "65/65 [==============================] - 155s 2s/step - loss: 0.5190 - acc: 0.7552 - val_loss: 0.3720 - val_acc: 0.8388\n",
            "Epoch 18/20\n",
            "65/65 [==============================] - 148s 2s/step - loss: 0.5005 - acc: 0.7616 - val_loss: 0.3724 - val_acc: 0.8437\n",
            "Epoch 19/20\n",
            "65/65 [==============================] - 152s 2s/step - loss: 0.4849 - acc: 0.7679 - val_loss: 0.3627 - val_acc: 0.8632\n",
            "Epoch 20/20\n",
            "65/65 [==============================] - 148s 2s/step - loss: 0.4908 - acc: 0.7699 - val_loss: 0.3629 - val_acc: 0.8474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "vK1yUMbEz4Wd",
        "outputId": "20ae3c70-c1b3-4852-c114-79436fdf2730"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2a1f94d895e5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2  # OpenCV for image resizing\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the path to the image\n",
        "test_dir = '/content/gdrive/MyDrive/faces2/Validation/male/079591.jpg.jpg'\n",
        "\n",
        "# Load the image using OpenCV and resize it to the desired target size\n",
        "target_size = (150, 150)\n",
        "img = cv2.imread(test_dir)\n",
        "img = cv2.resize(img, target_size)\n",
        "\n",
        "# Rescale the image to the range [0, 1]\n",
        "img = img / 255.0\n",
        "\n",
        "# Create a single-image generator\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_generator = test_datagen.flow(\n",
        "    x=np.array([img]),  # Pass the resized image as a NumPy array\n",
        "    y=None,  # No labels needed for inference\n",
        "    batch_size=1,  # Set batch size to 1 for a single image\n",
        "    shuffle=False,  # No need to shuffle for inference\n",
        "    # You can add more image augmentation options here if needed\n",
        ")\n",
        "\n",
        "# Make predictions using your model\n",
        "y_pred = model.predict(test_generator)\n",
        "\n",
        "# The 'predictions' variable now contains the model's predictions for the single image\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "print(y_pred_classes)"
      ],
      "metadata": {
        "id": "9ndz4jDCIAYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150,150),\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdtAxZJmIGa-",
        "outputId": "a357ce86-ebe9-4959-9472-c797d778dad5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 819 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_pred is the output of your model's prediction\n",
        "y_pred = model.predict(test_generator)\n",
        "\n",
        "# Convert probabilities to class labels (assuming binary classification)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Ensure y_pred_classes has the same number of samples as your test data\n",
        "assert y_pred_classes.shape[0] == test_generator.samples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7a1AHVCIJpz",
        "outputId": "c3e7d5f0-2b94-4f57-85a7-b2ceb87667e0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 11s 403ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(test_generator.classes, y_pred_classes)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_eSu-OoIMAS",
        "outputId": "f0f73ed4-1581-4971-f59a-b5c76fd5d304"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.61      0.54       408\n",
            "           1       0.49      0.37      0.43       411\n",
            "\n",
            "    accuracy                           0.49       819\n",
            "   macro avg       0.49      0.49      0.49       819\n",
            "weighted avg       0.49      0.49      0.48       819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained your Keras model and it's stored in a variable 'model'\n",
        "import pickle\n",
        "\n",
        "# Save the model to a file using pickle\n",
        "with open('model_CNN_Faces.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Ih4dppL7IP8y",
        "outputId": "f18f9d09-0a43-4e5d-fcdf-9bd38fdece55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-26c425493b33>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the model to a file using pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_CNN_Faces.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion = confusion_matrix(test_generator.classes, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjeoQxAzMxQV",
        "outputId": "1e46a32f-e59a-48c5-e12b-b84dbae9d4c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[249 159]\n",
            " [257 154]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FFmKXwm6M1dT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}